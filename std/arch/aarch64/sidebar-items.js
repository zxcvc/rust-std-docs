initSidebarItems({"constant":[["_PREFETCH_LOCALITY0","See `prefetch`."],["_PREFETCH_LOCALITY1","See `prefetch`."],["_PREFETCH_LOCALITY2","See `prefetch`."],["_PREFETCH_LOCALITY3","See `prefetch`."],["_PREFETCH_READ","See `prefetch`."],["_PREFETCH_WRITE","See `prefetch`."],["_TMFAILURE_CNCL","Transaction executed a TCANCEL instruction"],["_TMFAILURE_DBG","Transaction aborted due to a debug trap."],["_TMFAILURE_ERR","Transaction aborted because a non-permissible operation was attempted"],["_TMFAILURE_IMP","Fallback error type for any other reason"],["_TMFAILURE_INT","Transaction failed from interrupt"],["_TMFAILURE_MEM","Transaction aborted because a conflict occurred"],["_TMFAILURE_NEST","Transaction aborted due to transactional nesting level was exceeded"],["_TMFAILURE_REASON","Extraction mask for failure reason"],["_TMFAILURE_RTRY","Transaction retry is possible."],["_TMFAILURE_SIZE","Transaction aborted due to read or write set limit was exceeded"],["_TMFAILURE_TRIVIAL","Indicates a TRIVIAL version of TM is available"],["_TMSTART_SUCCESS","Transaction successfully started."]],"fn":[["__breakpoint","Inserts a breakpoint instruction."],["__crc32b","CRC32 single round checksum for bytes (8 bits)."],["__crc32cb","CRC32-C single round checksum for bytes (8 bits)."],["__crc32cd","CRC32-C single round checksum for quad words (64 bits)."],["__crc32ch","CRC32-C single round checksum for half words (16 bits)."],["__crc32cw","CRC32-C single round checksum for words (32 bits)."],["__crc32d","CRC32 single round checksum for quad words (64 bits)."],["__crc32h","CRC32 single round checksum for half words (16 bits)."],["__crc32w","CRC32 single round checksum for words (32 bits)."],["__dmb","Generates a DMB (data memory barrier) instruction or equivalent CP15 instruction."],["__dsb","Generates a DSB (data synchronization barrier) instruction or equivalent CP15 instruction."],["__isb","Generates an ISB (instruction synchronization barrier) instruction or equivalent CP15 instruction."],["__nop","Generates an unspecified no-op instruction."],["__rsr","Reads a 32-bit system register"],["__rsr64","Reads a 64-bit system register"],["__rsrp","Reads a system register containing an address"],["__sev","Generates a SEV (send a global event) hint instruction."],["__sevl","Generates a send a local event hint instruction."],["__tcancel","Cancels the current transaction and discards all state modifications that were performed transactionally."],["__tcommit","Commits the current transaction. For a nested transaction, the only effect is that the transactional nesting depth is decreased. For an outer transaction, the state modifications performed transactionally are committed to the architectural state."],["__tstart","Starts a new transaction. When the transaction starts successfully the return value is 0. If the transaction fails, all state modifications are discarded and a cause of the failure is encoded in the return value."],["__ttest","Tests if executing inside a transaction. If no transaction is currently executing, the return value is 0. Otherwise, this intrinsic returns the depth of the transaction."],["__wfe","Generates a WFE (wait for event) hint instruction, or nothing."],["__wfi","Generates a WFI (wait for interrupt) hint instruction, or nothing."],["__wsr","Writes a 32-bit system register"],["__wsr64","Writes a 64-bit system register"],["__wsrp","Writes a system register containing an address"],["__yield","Generates a YIELD hint instruction."],["_cls_u32","Counts the leading most significant bits set."],["_cls_u64","Counts the leading most significant bits set."],["_clz_u16","Count Leading Zeros."],["_clz_u32","Count Leading Zeros."],["_clz_u64","Count Leading Zeros."],["_clz_u8","Count Leading Zeros."],["_prefetch","Fetch the cache line that contains address `p` using the given `rw` and `locality`."],["_rbit_u32","Reverse the bit order."],["_rbit_u64","Reverse the bit order."],["_rev_u16","Reverse the order of the bytes."],["_rev_u32","Reverse the order of the bytes."],["_rev_u64","Reverse the order of the bytes."],["brk","Generates the trap instruction `BRK 1`"],["vabs_s16","Absolute value (wrapping)."],["vabs_s32","Absolute value (wrapping)."],["vabs_s64","Absolute Value (wrapping)."],["vabs_s8","Absolute value (wrapping)."],["vabsd_s64","Absolute Value (wrapping)."],["vabsq_s16","Absolute value (wrapping)."],["vabsq_s32","Absolute value (wrapping)."],["vabsq_s64","Absolute Value (wrapping)."],["vabsq_s8","Absolute value (wrapping)."],["vadd_f32","Vector add."],["vadd_f64","Vector add."],["vadd_s16","Vector add."],["vadd_s32","Vector add."],["vadd_s64","Vector add."],["vadd_s8","Vector add."],["vadd_u16","Vector add."],["vadd_u32","Vector add."],["vadd_u64","Vector add."],["vadd_u8","Vector add."],["vaddd_s64","Vector add."],["vaddd_u64","Vector add."],["vaddhn_high_s16","Add returning High Narrow (high half)."],["vaddhn_high_s32","Add returning High Narrow (high half)."],["vaddhn_high_s64","Add returning High Narrow (high half)."],["vaddhn_high_u16","Add returning High Narrow (high half)."],["vaddhn_high_u32","Add returning High Narrow (high half)."],["vaddhn_high_u64","Add returning High Narrow (high half)."],["vaddhn_s16","Add returning High Narrow."],["vaddhn_s32","Add returning High Narrow."],["vaddhn_s64","Add returning High Narrow."],["vaddhn_u16","Add returning High Narrow."],["vaddhn_u32","Add returning High Narrow."],["vaddhn_u64","Add returning High Narrow."],["vaddl_high_s16","Signed Add Long (vector, high half)."],["vaddl_high_s32","Signed Add Long (vector, high half)."],["vaddl_high_s8","Signed Add Long (vector, high half)."],["vaddl_high_u16","Unsigned Add Long (vector, high half)."],["vaddl_high_u32","Unsigned Add Long (vector, high half)."],["vaddl_high_u8","Unsigned Add Long (vector, high half)."],["vaddl_s16","Signed Add Long (vector)."],["vaddl_s32","Signed Add Long (vector)."],["vaddl_s8","Signed Add Long (vector)."],["vaddl_u16","Unsigned Add Long (vector)."],["vaddl_u32","Unsigned Add Long (vector)."],["vaddl_u8","Unsigned Add Long (vector)."],["vaddq_f32","Vector add."],["vaddq_f64","Vector add."],["vaddq_s16","Vector add."],["vaddq_s32","Vector add."],["vaddq_s64","Vector add."],["vaddq_s8","Vector add."],["vaddq_u16","Vector add."],["vaddq_u32","Vector add."],["vaddq_u64","Vector add."],["vaddq_u8","Vector add."],["vaddv_s16","Add across vector"],["vaddv_s32","Add across vector"],["vaddv_s8","Add across vector"],["vaddv_u16","Add across vector"],["vaddv_u32","Add across vector"],["vaddv_u8","Add across vector"],["vaddvq_s16","Add across vector"],["vaddvq_s32","Add across vector"],["vaddvq_s64","Add across vector"],["vaddvq_s8","Add across vector"],["vaddvq_u16","Add across vector"],["vaddvq_u32","Add across vector"],["vaddvq_u64","Add across vector"],["vaddvq_u8","Add across vector"],["vaddw_high_s16","Signed Add Wide (high half)."],["vaddw_high_s32","Signed Add Wide (high half)."],["vaddw_high_s8","Signed Add Wide (high half)."],["vaddw_high_u16","Unsigned Add Wide (high half)."],["vaddw_high_u32","Unsigned Add Wide (high half)."],["vaddw_high_u8","Unsigned Add Wide (high half)."],["vaddw_s16","Signed Add Wide."],["vaddw_s32","Signed Add Wide."],["vaddw_s8","Signed Add Wide."],["vaddw_u16","Unsigned Add Wide."],["vaddw_u32","Unsigned Add Wide."],["vaddw_u8","Unsigned Add Wide."],["vaesdq_u8","AES single round decryption."],["vaeseq_u8","AES single round encryption."],["vaesimcq_u8","AES inverse mix columns."],["vaesmcq_u8","AES mix columns."],["vand_s16","Vector bitwise and"],["vand_s32","Vector bitwise and"],["vand_s64","Vector bitwise and"],["vand_s8","Vector bitwise and"],["vand_u16","Vector bitwise and"],["vand_u32","Vector bitwise and"],["vand_u64","Vector bitwise and"],["vand_u8","Vector bitwise and"],["vandq_s16","Vector bitwise and"],["vandq_s32","Vector bitwise and"],["vandq_s64","Vector bitwise and"],["vandq_s8","Vector bitwise and"],["vandq_u16","Vector bitwise and"],["vandq_u32","Vector bitwise and"],["vandq_u64","Vector bitwise and"],["vandq_u8","Vector bitwise and"],["vceq_f32","Floating-point compare equal"],["vceq_f64","Floating-point compare equal"],["vceq_p64","Compare bitwise Equal (vector)"],["vceq_s16","Compare bitwise Equal (vector)"],["vceq_s32","Compare bitwise Equal (vector)"],["vceq_s64","Compare bitwise Equal (vector)"],["vceq_s8","Compare bitwise Equal (vector)"],["vceq_u16","Compare bitwise Equal (vector)"],["vceq_u32","Compare bitwise Equal (vector)"],["vceq_u64","Compare bitwise Equal (vector)"],["vceq_u8","Compare bitwise Equal (vector)"],["vceqq_f32","Floating-point compare equal"],["vceqq_f64","Floating-point compare equal"],["vceqq_p64","Compare bitwise Equal (vector)"],["vceqq_s16","Compare bitwise Equal (vector)"],["vceqq_s32","Compare bitwise Equal (vector)"],["vceqq_s64","Compare bitwise Equal (vector)"],["vceqq_s8","Compare bitwise Equal (vector)"],["vceqq_u16","Compare bitwise Equal (vector)"],["vceqq_u32","Compare bitwise Equal (vector)"],["vceqq_u64","Compare bitwise Equal (vector)"],["vceqq_u8","Compare bitwise Equal (vector)"],["vcge_f32","Floating-point compare greater than or equal"],["vcge_f64","Floating-point compare greater than or equal"],["vcge_s16","Compare signed greater than or equal"],["vcge_s32","Compare signed greater than or equal"],["vcge_s64","Compare signed greater than or equal"],["vcge_s8","Compare signed greater than or equal"],["vcge_u16","Compare unsigned greater than or equal"],["vcge_u32","Compare unsigned greater than or equal"],["vcge_u64","Compare unsigned greater than or equal"],["vcge_u8","Compare unsigned greater than or equal"],["vcgeq_f32","Floating-point compare greater than or equal"],["vcgeq_f64","Floating-point compare greater than or equal"],["vcgeq_s16","Compare signed greater than or equal"],["vcgeq_s32","Compare signed greater than or equal"],["vcgeq_s64","Compare signed greater than or equal"],["vcgeq_s8","Compare signed greater than or equal"],["vcgeq_u16","Compare unsigned greater than or equal"],["vcgeq_u32","Compare unsigned greater than or equal"],["vcgeq_u64","Compare unsigned greater than or equal"],["vcgeq_u8","Compare unsigned greater than or equal"],["vcgt_f32","Floating-point compare greater than"],["vcgt_f64","Floating-point compare greater than"],["vcgt_s16","Compare signed greater than"],["vcgt_s32","Compare signed greater than"],["vcgt_s64","Compare signed greater than"],["vcgt_s8","Compare signed greater than"],["vcgt_u16","Compare unsigned highe"],["vcgt_u32","Compare unsigned highe"],["vcgt_u64","Compare unsigned highe"],["vcgt_u8","Compare unsigned highe"],["vcgtq_f32","Floating-point compare greater than"],["vcgtq_f64","Floating-point compare greater than"],["vcgtq_s16","Compare signed greater than"],["vcgtq_s32","Compare signed greater than"],["vcgtq_s64","Compare signed greater than"],["vcgtq_s8","Compare signed greater than"],["vcgtq_u16","Compare unsigned highe"],["vcgtq_u32","Compare unsigned highe"],["vcgtq_u64","Compare unsigned highe"],["vcgtq_u8","Compare unsigned highe"],["vcle_f32","Floating-point compare less than or equal"],["vcle_f64","Floating-point compare less than or equal"],["vcle_s16","Compare signed less than or equal"],["vcle_s32","Compare signed less than or equal"],["vcle_s64","Compare signed less than or equal"],["vcle_s8","Compare signed less than or equal"],["vcle_u16","Compare unsigned less than or equal"],["vcle_u32","Compare unsigned less than or equal"],["vcle_u64","Compare unsigned less than or equal"],["vcle_u8","Compare unsigned less than or equal"],["vcleq_f32","Floating-point compare less than or equal"],["vcleq_f64","Floating-point compare less than or equal"],["vcleq_s16","Compare signed less than or equal"],["vcleq_s32","Compare signed less than or equal"],["vcleq_s64","Compare signed less than or equal"],["vcleq_s8","Compare signed less than or equal"],["vcleq_u16","Compare unsigned less than or equal"],["vcleq_u32","Compare unsigned less than or equal"],["vcleq_u64","Compare unsigned less than or equal"],["vcleq_u8","Compare unsigned less than or equal"],["vclt_f32","Floating-point compare less than"],["vclt_f64","Floating-point compare less than"],["vclt_s16","Compare signed less than"],["vclt_s32","Compare signed less than"],["vclt_s64","Compare signed less than"],["vclt_s8","Compare signed less than"],["vclt_u16","Compare unsigned less than"],["vclt_u32","Compare unsigned less than"],["vclt_u64","Compare unsigned less than"],["vclt_u8","Compare unsigned less than"],["vcltq_f32","Floating-point compare less than"],["vcltq_f64","Floating-point compare less than"],["vcltq_s16","Compare signed less than"],["vcltq_s32","Compare signed less than"],["vcltq_s64","Compare signed less than"],["vcltq_s8","Compare signed less than"],["vcltq_u16","Compare unsigned less than"],["vcltq_u32","Compare unsigned less than"],["vcltq_u64","Compare unsigned less than"],["vcltq_u8","Compare unsigned less than"],["vcnt_p8","Population count per byte."],["vcnt_s8","Population count per byte."],["vcnt_u8","Population count per byte."],["vcntq_p8","Population count per byte."],["vcntq_s8","Population count per byte."],["vcntq_u8","Population count per byte."],["vcombine_f32","Vector combine"],["vcombine_f64","Vector combine"],["vcombine_p16","Vector combine"],["vcombine_p64","Vector combine"],["vcombine_p8","Vector combine"],["vcombine_s16","Vector combine"],["vcombine_s32","Vector combine"],["vcombine_s64","Vector combine"],["vcombine_s8","Vector combine"],["vcombine_u16","Vector combine"],["vcombine_u32","Vector combine"],["vcombine_u64","Vector combine"],["vcombine_u8","Vector combine"],["vcvtq_s32_f32",""],["vcvtq_u32_f32","Floating-point Convert to Unsigned fixed-point, rounding toward Zero (vector)"],["vdupq_n_s8","Duplicate vector element to vector or scalar"],["vdupq_n_u8","Duplicate vector element to vector or scalar"],["veor_s16","Vector bitwise exclusive or (vector)"],["veor_s32","Vector bitwise exclusive or (vector)"],["veor_s64","Vector bitwise exclusive or (vector)"],["veor_s8","Vector bitwise exclusive or (vector)"],["veor_u16","Vector bitwise exclusive or (vector)"],["veor_u32","Vector bitwise exclusive or (vector)"],["veor_u64","Vector bitwise exclusive or (vector)"],["veor_u8","Vector bitwise exclusive or (vector)"],["veorq_s16","Vector bitwise exclusive or (vector)"],["veorq_s32","Vector bitwise exclusive or (vector)"],["veorq_s64","Vector bitwise exclusive or (vector)"],["veorq_s8","Vector bitwise exclusive or (vector)"],["veorq_u16","Vector bitwise exclusive or (vector)"],["veorq_u32","Vector bitwise exclusive or (vector)"],["veorq_u64","Vector bitwise exclusive or (vector)"],["veorq_u8","Vector bitwise exclusive or (vector)"],["vextq_s8","Extract vector from pair of vectors"],["vextq_u8","Extract vector from pair of vectors"],["vget_lane_u64","Move vector element to general-purpose register"],["vget_lane_u8","Move vector element to general-purpose register"],["vgetq_lane_s32","Move vector element to general-purpose register"],["vgetq_lane_u16","Move vector element to general-purpose register"],["vgetq_lane_u32","Move vector element to general-purpose register"],["vgetq_lane_u64","Move vector element to general-purpose register"],["vhadd_s16","Halving add"],["vhadd_s32","Halving add"],["vhadd_s8","Halving add"],["vhadd_u16","Halving add"],["vhadd_u32","Halving add"],["vhadd_u8","Halving add"],["vhaddq_s16","Halving add"],["vhaddq_s32","Halving add"],["vhaddq_s8","Halving add"],["vhaddq_u16","Halving add"],["vhaddq_u32","Halving add"],["vhaddq_u8","Halving add"],["vhsub_s16","Signed halving subtract"],["vhsub_s32","Signed halving subtract"],["vhsub_s8","Signed halving subtract"],["vhsub_u16","Signed halving subtract"],["vhsub_u32","Signed halving subtract"],["vhsub_u8","Signed halving subtract"],["vhsubq_s16","Signed halving subtract"],["vhsubq_s32","Signed halving subtract"],["vhsubq_s8","Signed halving subtract"],["vhsubq_u16","Signed halving subtract"],["vhsubq_u32","Signed halving subtract"],["vhsubq_u8","Signed halving subtract"],["vld1_dup_f32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_p16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_p8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_s16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_s32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_s64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_s8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_u16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_u32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_u64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_dup_u8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1_f32","Load multiple single-element structures to one, two, three, or four registers."],["vld1_f64","Load multiple single-element structures to one, two, three, or four registers."],["vld1_lane_f32","Load one single-element structure to one lane of one register."],["vld1_lane_p16","Load one single-element structure to one lane of one register."],["vld1_lane_p8","Load one single-element structure to one lane of one register."],["vld1_lane_s16","Load one single-element structure to one lane of one register."],["vld1_lane_s32","Load one single-element structure to one lane of one register."],["vld1_lane_s64","Load one single-element structure to one lane of one register."],["vld1_lane_s8","Load one single-element structure to one lane of one register."],["vld1_lane_u16","Load one single-element structure to one lane of one register."],["vld1_lane_u32","Load one single-element structure to one lane of one register."],["vld1_lane_u64","Load one single-element structure to one lane of one register."],["vld1_lane_u8","Load one single-element structure to one lane of one register."],["vld1_p16","Load multiple single-element structures to one, two, three, or four registers."],["vld1_p8","Load multiple single-element structures to one, two, three, or four registers."],["vld1_s16","Load multiple single-element structures to one, two, three, or four registers."],["vld1_s32","Load multiple single-element structures to one, two, three, or four registers."],["vld1_s64","Load multiple single-element structures to one, two, three, or four registers."],["vld1_s8","Load multiple single-element structures to one, two, three, or four registers."],["vld1_u16","Load multiple single-element structures to one, two, three, or four registers."],["vld1_u32","Load multiple single-element structures to one, two, three, or four registers."],["vld1_u64","Load multiple single-element structures to one, two, three, or four registers."],["vld1_u8","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_dup_f32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_p16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_p8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_s16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_s32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_s64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_s8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_u16","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_u32","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_u64","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_dup_u8","Load one single-element structure and Replicate to all lanes (of one register)."],["vld1q_f32","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_f64","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_lane_f32","Load one single-element structure to one lane of one register."],["vld1q_lane_p16","Load one single-element structure to one lane of one register."],["vld1q_lane_p8","Load one single-element structure to one lane of one register."],["vld1q_lane_s16","Load one single-element structure to one lane of one register."],["vld1q_lane_s32","Load one single-element structure to one lane of one register."],["vld1q_lane_s64","Load one single-element structure to one lane of one register."],["vld1q_lane_s8","Load one single-element structure to one lane of one register."],["vld1q_lane_u16","Load one single-element structure to one lane of one register."],["vld1q_lane_u32","Load one single-element structure to one lane of one register."],["vld1q_lane_u64","Load one single-element structure to one lane of one register."],["vld1q_lane_u8","Load one single-element structure to one lane of one register."],["vld1q_p16","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_p8","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_s16","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_s32","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_s64","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_s8","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_u16","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_u32","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_u64","Load multiple single-element structures to one, two, three, or four registers."],["vld1q_u8","Load multiple single-element structures to one, two, three, or four registers."],["vmax_f32","Maximum (vector)"],["vmax_f64","Maximum (vector)"],["vmax_s16","Maximum (vector)"],["vmax_s32","Maximum (vector)"],["vmax_s8","Maximum (vector)"],["vmax_u16","Maximum (vector)"],["vmax_u32","Maximum (vector)"],["vmax_u8","Maximum (vector)"],["vmaxq_f32","Maximum (vector)"],["vmaxq_f64","Maximum (vector)"],["vmaxq_s16","Maximum (vector)"],["vmaxq_s32","Maximum (vector)"],["vmaxq_s8","Maximum (vector)"],["vmaxq_u16","Maximum (vector)"],["vmaxq_u32","Maximum (vector)"],["vmaxq_u8","Maximum (vector)"],["vmaxv_f32","Horizontal vector max."],["vmaxv_s16","Horizontal vector max."],["vmaxv_s32","Horizontal vector max."],["vmaxv_s8","Horizontal vector max."],["vmaxv_u16","Horizontal vector max."],["vmaxv_u32","Horizontal vector max."],["vmaxv_u8","Horizontal vector max."],["vmaxvq_f32","Horizontal vector max."],["vmaxvq_f64","Horizontal vector max."],["vmaxvq_s16","Horizontal vector max."],["vmaxvq_s32","Horizontal vector max."],["vmaxvq_s8","Horizontal vector max."],["vmaxvq_u16","Horizontal vector max."],["vmaxvq_u32","Horizontal vector max."],["vmaxvq_u8","Horizontal vector max."],["vmin_f32","Minimum (vector)"],["vmin_f64","Minimum (vector)"],["vmin_s16","Minimum (vector)"],["vmin_s32","Minimum (vector)"],["vmin_s8","Minimum (vector)"],["vmin_u16","Minimum (vector)"],["vmin_u32","Minimum (vector)"],["vmin_u8","Minimum (vector)"],["vminq_f32","Minimum (vector)"],["vminq_f64","Minimum (vector)"],["vminq_s16","Minimum (vector)"],["vminq_s32","Minimum (vector)"],["vminq_s8","Minimum (vector)"],["vminq_u16","Minimum (vector)"],["vminq_u32","Minimum (vector)"],["vminq_u8","Minimum (vector)"],["vminv_f32","Horizontal vector min."],["vminv_s16","Horizontal vector min."],["vminv_s32","Horizontal vector min."],["vminv_s8","Horizontal vector min."],["vminv_u16","Horizontal vector min."],["vminv_u32","Horizontal vector min."],["vminv_u8","Horizontal vector min."],["vminvq_f32","Horizontal vector min."],["vminvq_f64","Horizontal vector min."],["vminvq_s16","Horizontal vector min."],["vminvq_s32","Horizontal vector min."],["vminvq_s8","Horizontal vector min."],["vminvq_u16","Horizontal vector min."],["vminvq_u32","Horizontal vector min."],["vminvq_u8","Horizontal vector min."],["vmovl_s16","Vector long move."],["vmovl_s32","Vector long move."],["vmovl_s8","Vector long move."],["vmovl_u16","Vector long move."],["vmovl_u32","Vector long move."],["vmovl_u8","Vector long move."],["vmovn_s16","Vector narrow integer."],["vmovn_s32","Vector narrow integer."],["vmovn_s64","Vector narrow integer."],["vmovn_u16","Vector narrow integer."],["vmovn_u32","Vector narrow integer."],["vmovn_u64","Vector narrow integer."],["vmovq_n_u8","Duplicate vector element to vector or scalar"],["vmul_f32","Multiply"],["vmul_f64","Multiply"],["vmul_s16","Multiply"],["vmul_s32","Multiply"],["vmul_s8","Multiply"],["vmul_u16","Multiply"],["vmul_u32","Multiply"],["vmul_u8","Multiply"],["vmull_p64","Polynomial multiply long"],["vmulq_f32","Multiply"],["vmulq_f64","Multiply"],["vmulq_s16","Multiply"],["vmulq_s32","Multiply"],["vmulq_s8","Multiply"],["vmulq_u16","Multiply"],["vmulq_u32","Multiply"],["vmulq_u8","Multiply"],["vmvn_p8","Vector bitwise not."],["vmvn_s16","Vector bitwise not."],["vmvn_s32","Vector bitwise not."],["vmvn_s8","Vector bitwise not."],["vmvn_u16","Vector bitwise not."],["vmvn_u32","Vector bitwise not."],["vmvn_u8","Vector bitwise not."],["vmvnq_p8","Vector bitwise not."],["vmvnq_s16","Vector bitwise not."],["vmvnq_s32","Vector bitwise not."],["vmvnq_s8","Vector bitwise not."],["vmvnq_u16","Vector bitwise not."],["vmvnq_u32","Vector bitwise not."],["vmvnq_u8","Vector bitwise not."],["vorr_s16","Vector bitwise or (immediate, inclusive)"],["vorr_s32","Vector bitwise or (immediate, inclusive)"],["vorr_s64","Vector bitwise or (immediate, inclusive)"],["vorr_s8","Vector bitwise or (immediate, inclusive)"],["vorr_u16","Vector bitwise or (immediate, inclusive)"],["vorr_u32","Vector bitwise or (immediate, inclusive)"],["vorr_u64","Vector bitwise or (immediate, inclusive)"],["vorr_u8","Vector bitwise or (immediate, inclusive)"],["vorrq_s16","Vector bitwise or (immediate, inclusive)"],["vorrq_s32","Vector bitwise or (immediate, inclusive)"],["vorrq_s64","Vector bitwise or (immediate, inclusive)"],["vorrq_s8","Vector bitwise or (immediate, inclusive)"],["vorrq_u16","Vector bitwise or (immediate, inclusive)"],["vorrq_u32","Vector bitwise or (immediate, inclusive)"],["vorrq_u64","Vector bitwise or (immediate, inclusive)"],["vorrq_u8","Vector bitwise or (immediate, inclusive)"],["vpadal_s16","Signed Add and Accumulate Long Pairwise."],["vpadal_s32","Signed Add and Accumulate Long Pairwise."],["vpadal_s8","Signed Add and Accumulate Long Pairwise."],["vpadal_u16","Unsigned Add and Accumulate Long Pairwise."],["vpadal_u32","Unsigned Add and Accumulate Long Pairwise."],["vpadal_u8","Unsigned Add and Accumulate Long Pairwise."],["vpadalq_s16","Signed Add and Accumulate Long Pairwise."],["vpadalq_s32","Signed Add and Accumulate Long Pairwise."],["vpadalq_s8","Signed Add and Accumulate Long Pairwise."],["vpadalq_u16","Unsigned Add and Accumulate Long Pairwise."],["vpadalq_u32","Unsigned Add and Accumulate Long Pairwise."],["vpadalq_u8","Unsigned Add and Accumulate Long Pairwise."],["vpadd_s16","Add pairwise."],["vpadd_s32","Add pairwise."],["vpadd_s8","Add pairwise."],["vpadd_u16","Add pairwise."],["vpadd_u32","Add pairwise."],["vpadd_u8","Add pairwise."],["vpaddd_s64","Add pairwise"],["vpaddd_u64","Add pairwise"],["vpaddl_s16","Signed Add Long Pairwise."],["vpaddl_s32","Signed Add Long Pairwise."],["vpaddl_s8","Signed Add Long Pairwise."],["vpaddl_u16","Unsigned Add Long Pairwise."],["vpaddl_u32","Unsigned Add Long Pairwise."],["vpaddl_u8","Unsigned Add Long Pairwise."],["vpaddlq_s16","Signed Add Long Pairwise."],["vpaddlq_s32","Signed Add Long Pairwise."],["vpaddlq_s8","Signed Add Long Pairwise."],["vpaddlq_u16","Unsigned Add Long Pairwise."],["vpaddlq_u32","Unsigned Add Long Pairwise."],["vpaddlq_u8","Unsigned Add Long Pairwise."],["vpaddq_s16","Add pairwise"],["vpaddq_s32","Add pairwise"],["vpaddq_s8","Add pairwise"],["vpaddq_u16","Add pairwise"],["vpaddq_u32","Add pairwise"],["vpaddq_u8","Add pairwise"],["vpmax_f32","Folding maximum of adjacent pairs"],["vpmax_s16","Folding maximum of adjacent pairs"],["vpmax_s32","Folding maximum of adjacent pairs"],["vpmax_s8","Folding maximum of adjacent pairs"],["vpmax_u16","Folding maximum of adjacent pairs"],["vpmax_u32","Folding maximum of adjacent pairs"],["vpmax_u8","Folding maximum of adjacent pairs"],["vpmaxq_f32","Folding maximum of adjacent pairs"],["vpmaxq_f64","Folding maximum of adjacent pairs"],["vpmaxq_s16","Folding maximum of adjacent pairs"],["vpmaxq_s32","Folding maximum of adjacent pairs"],["vpmaxq_s8","Folding maximum of adjacent pairs"],["vpmaxq_u16","Folding maximum of adjacent pairs"],["vpmaxq_u32","Folding maximum of adjacent pairs"],["vpmaxq_u8","Folding maximum of adjacent pairs"],["vpmin_f32","Folding minimum of adjacent pairs"],["vpmin_s16","Folding minimum of adjacent pairs"],["vpmin_s32","Folding minimum of adjacent pairs"],["vpmin_s8","Folding minimum of adjacent pairs"],["vpmin_u16","Folding minimum of adjacent pairs"],["vpmin_u32","Folding minimum of adjacent pairs"],["vpmin_u8","Folding minimum of adjacent pairs"],["vpminq_f32","Folding minimum of adjacent pairs"],["vpminq_f64","Folding minimum of adjacent pairs"],["vpminq_s16","Folding minimum of adjacent pairs"],["vpminq_s32","Folding minimum of adjacent pairs"],["vpminq_s8","Folding minimum of adjacent pairs"],["vpminq_u16","Folding minimum of adjacent pairs"],["vpminq_u32","Folding minimum of adjacent pairs"],["vpminq_u8","Folding minimum of adjacent pairs"],["vqadd_s16","Saturating add"],["vqadd_s32","Saturating add"],["vqadd_s8","Saturating add"],["vqadd_u16","Saturating add"],["vqadd_u32","Saturating add"],["vqadd_u8","Saturating add"],["vqaddq_s16","Saturating add"],["vqaddq_s32","Saturating add"],["vqaddq_s8","Saturating add"],["vqaddq_u16","Saturating add"],["vqaddq_u32","Saturating add"],["vqaddq_u8","Saturating add"],["vqmovn_u64","Unsigned saturating extract narrow."],["vqsub_s16","Saturating subtract"],["vqsub_s32","Saturating subtract"],["vqsub_s8","Saturating subtract"],["vqsub_u16","Saturating subtract"],["vqsub_u32","Saturating subtract"],["vqsub_u8","Saturating subtract"],["vqsubq_s16","Saturating subtract"],["vqsubq_s32","Saturating subtract"],["vqsubq_s8","Saturating subtract"],["vqsubq_u16","Saturating subtract"],["vqsubq_u32","Saturating subtract"],["vqsubq_u8","Saturating subtract"],["vqtbl1_p8","Table look-up"],["vqtbl1_s8","Table look-up"],["vqtbl1_u8","Table look-up"],["vqtbl1q_p8","Table look-up"],["vqtbl1q_s8","Table look-up"],["vqtbl1q_u8","Table look-up"],["vqtbl2_p8","Table look-up"],["vqtbl2_s8","Table look-up"],["vqtbl2_u8","Table look-up"],["vqtbl2q_p8","Table look-up"],["vqtbl2q_s8","Table look-up"],["vqtbl2q_u8","Table look-up"],["vqtbl3_p8","Table look-up"],["vqtbl3_s8","Table look-up"],["vqtbl3_u8","Table look-up"],["vqtbl3q_p8","Table look-up"],["vqtbl3q_s8","Table look-up"],["vqtbl3q_u8","Table look-up"],["vqtbl4_p8","Table look-up"],["vqtbl4_s8","Table look-up"],["vqtbl4_u8","Table look-up"],["vqtbl4q_p8","Table look-up"],["vqtbl4q_s8","Table look-up"],["vqtbl4q_u8","Table look-up"],["vqtbx1_p8","Extended table look-up"],["vqtbx1_s8","Extended table look-up"],["vqtbx1_u8","Extended table look-up"],["vqtbx1q_p8","Extended table look-up"],["vqtbx1q_s8","Extended table look-up"],["vqtbx1q_u8","Extended table look-up"],["vqtbx2_p8","Extended table look-up"],["vqtbx2_s8","Extended table look-up"],["vqtbx2_u8","Extended table look-up"],["vqtbx2q_p8","Extended table look-up"],["vqtbx2q_s8","Extended table look-up"],["vqtbx2q_u8","Extended table look-up"],["vqtbx3_p8","Extended table look-up"],["vqtbx3_s8","Extended table look-up"],["vqtbx3_u8","Extended table look-up"],["vqtbx3q_p8","Extended table look-up"],["vqtbx3q_s8","Extended table look-up"],["vqtbx3q_u8","Extended table look-up"],["vqtbx4_p8","Extended table look-up"],["vqtbx4_s8","Extended table look-up"],["vqtbx4_u8","Extended table look-up"],["vqtbx4q_p8","Extended table look-up"],["vqtbx4q_s8","Extended table look-up"],["vqtbx4q_u8","Extended table look-up"],["vraddhn_high_s16","Rounding Add returning High Narrow (high half)."],["vraddhn_high_s32","Rounding Add returning High Narrow (high half)."],["vraddhn_high_s64","Rounding Add returning High Narrow (high half)."],["vraddhn_high_u16","Rounding Add returning High Narrow (high half)."],["vraddhn_high_u32","Rounding Add returning High Narrow (high half)."],["vraddhn_high_u64","Rounding Add returning High Narrow (high half)."],["vraddhn_s16","Rounding Add returning High Narrow."],["vraddhn_s32","Rounding Add returning High Narrow."],["vraddhn_s64","Rounding Add returning High Narrow."],["vraddhn_u16","Rounding Add returning High Narrow."],["vraddhn_u32","Rounding Add returning High Narrow."],["vraddhn_u64","Rounding Add returning High Narrow."],["vreinterpret_u64_u32","Vector reinterpret cast operation"],["vreinterpretq_s8_u8","Vector reinterpret cast operation"],["vreinterpretq_u16_u8","Vector reinterpret cast operation"],["vreinterpretq_u32_u8","Vector reinterpret cast operation"],["vreinterpretq_u64_u8","Vector reinterpret cast operation"],["vreinterpretq_u8_s8","Vector reinterpret cast operation"],["vrev16_p8","Reversing vector elements (swap endianness)"],["vrev16_s8","Reversing vector elements (swap endianness)"],["vrev16_u8","Reversing vector elements (swap endianness)"],["vrev16q_p8","Reversing vector elements (swap endianness)"],["vrev16q_s8","Reversing vector elements (swap endianness)"],["vrev16q_u8","Reversing vector elements (swap endianness)"],["vrev32_p8","Reversing vector elements (swap endianness)"],["vrev32_s8","Reversing vector elements (swap endianness)"],["vrev32_u16","Reversing vector elements (swap endianness)"],["vrev32_u8","Reversing vector elements (swap endianness)"],["vrev32q_p8","Reversing vector elements (swap endianness)"],["vrev32q_s8","Reversing vector elements (swap endianness)"],["vrev32q_u16","Reversing vector elements (swap endianness)"],["vrev32q_u8","Reversing vector elements (swap endianness)"],["vrev64_f32","Reversing vector elements (swap endianness)"],["vrev64_p16","Reversing vector elements (swap endianness)"],["vrev64_p8","Reversing vector elements (swap endianness)"],["vrev64_s16","Reversing vector elements (swap endianness)"],["vrev64_s32","Reversing vector elements (swap endianness)"],["vrev64_s8","Reversing vector elements (swap endianness)"],["vrev64_u16","Reversing vector elements (swap endianness)"],["vrev64_u32","Reversing vector elements (swap endianness)"],["vrev64_u8","Reversing vector elements (swap endianness)"],["vrev64q_f32","Reversing vector elements (swap endianness)"],["vrev64q_p16","Reversing vector elements (swap endianness)"],["vrev64q_p8","Reversing vector elements (swap endianness)"],["vrev64q_s16","Reversing vector elements (swap endianness)"],["vrev64q_s32","Reversing vector elements (swap endianness)"],["vrev64q_s8","Reversing vector elements (swap endianness)"],["vrev64q_u16","Reversing vector elements (swap endianness)"],["vrev64q_u32","Reversing vector elements (swap endianness)"],["vrev64q_u8","Reversing vector elements (swap endianness)"],["vrhadd_s16","Rounding halving add"],["vrhadd_s32","Rounding halving add"],["vrhadd_s8","Rounding halving add"],["vrhadd_u16","Rounding halving add"],["vrhadd_u32","Rounding halving add"],["vrhadd_u8","Rounding halving add"],["vrhaddq_s16","Rounding halving add"],["vrhaddq_s32","Rounding halving add"],["vrhaddq_s8","Rounding halving add"],["vrhaddq_u16","Rounding halving add"],["vrhaddq_u32","Rounding halving add"],["vrhaddq_u8","Rounding halving add"],["vrsqrte_f32","Reciprocal square-root estimate."],["vsha1cq_u32","SHA1 hash update accelerator, choose."],["vsha1h_u32","SHA1 fixed rotate."],["vsha1mq_u32","SHA1 hash update accelerator, majority."],["vsha1pq_u32","SHA1 hash update accelerator, parity."],["vsha1su0q_u32","SHA1 schedule update accelerator, first part."],["vsha1su1q_u32","SHA1 schedule update accelerator, second part."],["vsha256h2q_u32","SHA256 hash update accelerator, upper part."],["vsha256hq_u32","SHA256 hash update accelerator."],["vsha256su0q_u32","SHA256 schedule update accelerator, first part."],["vsha256su1q_u32","SHA256 schedule update accelerator, second part."],["vshlq_n_u8","Shift right"],["vshrq_n_u8","Unsigned shift right"],["vsli_n_p16","Shift Left and Insert (immediate)"],["vsli_n_p8","Shift Left and Insert (immediate)"],["vsli_n_s16","Shift Left and Insert (immediate)"],["vsli_n_s32","Shift Left and Insert (immediate)"],["vsli_n_s64","Shift Left and Insert (immediate)"],["vsli_n_s8","Shift Left and Insert (immediate)"],["vsli_n_u16","Shift Left and Insert (immediate)"],["vsli_n_u32","Shift Left and Insert (immediate)"],["vsli_n_u64","Shift Left and Insert (immediate)"],["vsli_n_u8","Shift Left and Insert (immediate)"],["vsliq_n_p16","Shift Left and Insert (immediate)"],["vsliq_n_p8","Shift Left and Insert (immediate)"],["vsliq_n_s16","Shift Left and Insert (immediate)"],["vsliq_n_s32","Shift Left and Insert (immediate)"],["vsliq_n_s64","Shift Left and Insert (immediate)"],["vsliq_n_s8","Shift Left and Insert (immediate)"],["vsliq_n_u16","Shift Left and Insert (immediate)"],["vsliq_n_u32","Shift Left and Insert (immediate)"],["vsliq_n_u64","Shift Left and Insert (immediate)"],["vsliq_n_u8","Shift Left and Insert (immediate)"],["vsqadd_u16","Unsigned saturating Accumulate of Signed value."],["vsqadd_u32","Unsigned saturating Accumulate of Signed value."],["vsqadd_u64","Unsigned saturating Accumulate of Signed value."],["vsqadd_u8","Unsigned saturating Accumulate of Signed value."],["vsqaddq_u16","Unsigned saturating Accumulate of Signed value."],["vsqaddq_u32","Unsigned saturating Accumulate of Signed value."],["vsqaddq_u64","Unsigned saturating Accumulate of Signed value."],["vsqaddq_u8","Unsigned saturating Accumulate of Signed value."],["vsri_n_p16","Shift Right and Insert (immediate)"],["vsri_n_p8","Shift Right and Insert (immediate)"],["vsri_n_s16","Shift Right and Insert (immediate)"],["vsri_n_s32","Shift Right and Insert (immediate)"],["vsri_n_s64","Shift Right and Insert (immediate)"],["vsri_n_s8","Shift Right and Insert (immediate)"],["vsri_n_u16","Shift Right and Insert (immediate)"],["vsri_n_u32","Shift Right and Insert (immediate)"],["vsri_n_u64","Shift Right and Insert (immediate)"],["vsri_n_u8","Shift Right and Insert (immediate)"],["vsriq_n_p16","Shift Right and Insert (immediate)"],["vsriq_n_p8","Shift Right and Insert (immediate)"],["vsriq_n_s16","Shift Right and Insert (immediate)"],["vsriq_n_s32","Shift Right and Insert (immediate)"],["vsriq_n_s64","Shift Right and Insert (immediate)"],["vsriq_n_s8","Shift Right and Insert (immediate)"],["vsriq_n_u16","Shift Right and Insert (immediate)"],["vsriq_n_u32","Shift Right and Insert (immediate)"],["vsriq_n_u64","Shift Right and Insert (immediate)"],["vsriq_n_u8","Shift Right and Insert (immediate)"],["vsub_f32","Subtract"],["vsub_f64","Subtract"],["vsub_s16","Subtract"],["vsub_s32","Subtract"],["vsub_s64","Subtract"],["vsub_s8","Subtract"],["vsub_u16","Subtract"],["vsub_u32","Subtract"],["vsub_u64","Subtract"],["vsub_u8","Subtract"],["vsubq_f32","Subtract"],["vsubq_f64","Subtract"],["vsubq_s16","Subtract"],["vsubq_s32","Subtract"],["vsubq_s64","Subtract"],["vsubq_s8","Subtract"],["vsubq_u16","Subtract"],["vsubq_u32","Subtract"],["vsubq_u64","Subtract"],["vsubq_u8","Subtract"],["vtbl1_p8","Table look-up"],["vtbl1_s8","Table look-up"],["vtbl1_u8","Table look-up"],["vtbl2_p8","Table look-up"],["vtbl2_s8","Table look-up"],["vtbl2_u8","Table look-up"],["vtbl3_p8","Table look-up"],["vtbl3_s8","Table look-up"],["vtbl3_u8","Table look-up"],["vtbl4_p8","Table look-up"],["vtbl4_s8","Table look-up"],["vtbl4_u8","Table look-up"],["vtbx1_p8","Extended table look-up"],["vtbx1_s8","Extended table look-up"],["vtbx1_u8","Extended table look-up"],["vtbx2_p8","Extended table look-up"],["vtbx2_s8","Extended table look-up"],["vtbx2_u8","Extended table look-up"],["vtbx3_p8","Extended table look-up"],["vtbx3_s8","Extended table look-up"],["vtbx3_u8","Extended table look-up"],["vtbx4_p8","Extended table look-up"],["vtbx4_s8","Extended table look-up"],["vtbx4_u8","Extended table look-up"],["vuqadd_s16","Signed saturating Accumulate of Unsigned value."],["vuqadd_s32","Signed saturating Accumulate of Unsigned value."],["vuqadd_s64","Signed saturating Accumulate of Unsigned value."],["vuqadd_s8","Signed saturating Accumulate of Unsigned value."],["vuqaddq_s16","Signed saturating Accumulate of Unsigned value."],["vuqaddq_s32","Signed saturating Accumulate of Unsigned value."],["vuqaddq_s64","Signed saturating Accumulate of Unsigned value."],["vuqaddq_s8","Signed saturating Accumulate of Unsigned value."]],"struct":[["ISH","Inner Shareable is the required shareability domain, reads and writes are the required access types"],["ISHLD","Inner Shareable is the required shareability domain, reads are the required access type"],["ISHST","Inner Shareable is the required shareability domain, writes are the required access type"],["LD","Full system is the required shareability domain, reads are the required access type"],["NSH","Non-shareable is the required shareability domain, reads and writes are the required access types"],["NSHLD","Non-shareable is the required shareability domain, reads are the required access type"],["NSHST","Non-shareable is the required shareability domain, writes are the required access type"],["OSH","Outer Shareable is the required shareability domain, reads and writes are the required access types"],["OSHLD","Outher Shareable is the required shareability domain, reads are the required access type"],["OSHST","Outer Shareable is the required shareability domain, writes are the required access type"],["ST","Full system is the required shareability domain, writes are the required access type"],["SY","Full system is the required shareability domain, reads and writes are the required access types"],["float32x2_t","ARM-specific 64-bit wide vector of two packed `f32`."],["float32x4_t","ARM-specific 128-bit wide vector of four packed `f32`."],["float64x1_t","ARM-specific 64-bit wide vector of one packed `f64`."],["float64x2_t","ARM-specific 128-bit wide vector of two packed `f64`."],["int16x4_t","ARM-specific 64-bit wide vector of four packed `i16`."],["int16x8_t","ARM-specific 128-bit wide vector of eight packed `i16`."],["int32x2_t","ARM-specific 64-bit wide vector of two packed `i32`."],["int32x4_t","ARM-specific 128-bit wide vector of four packed `i32`."],["int64x1_t","ARM-specific 64-bit wide vector of one packed `i64`."],["int64x2_t","ARM-specific 128-bit wide vector of two packed `i64`."],["int8x16_t","ARM-specific 128-bit wide vector of sixteen packed `i8`."],["int8x16x2_t","ARM-specific type containing two `int8x16_t` vectors."],["int8x16x3_t","ARM-specific type containing three `int8x16_t` vectors."],["int8x16x4_t","ARM-specific type containing four `int8x16_t` vectors."],["int8x8_t","ARM-specific 64-bit wide vector of eight packed `i8`."],["int8x8x2_t","ARM-specific type containing two `int8x8_t` vectors."],["int8x8x3_t","ARM-specific type containing three `int8x8_t` vectors."],["int8x8x4_t","ARM-specific type containing four `int8x8_t` vectors."],["poly16x4_t","ARM-specific 64-bit wide vector of four packed `p16`."],["poly16x8_t","ARM-specific 128-bit wide vector of eight packed `p16`."],["poly64x1_t","ARM-specific 64-bit wide vector of one packed `p64`."],["poly64x2_t","ARM-specific 128-bit wide vector of two packed `p64`."],["poly8x16_t","ARM-specific 128-bit wide vector of sixteen packed `p8`."],["poly8x16x2_t","ARM-specific type containing two `poly8x16_t` vectors."],["poly8x16x3_t","ARM-specific type containing three `poly8x16_t` vectors."],["poly8x16x4_t","ARM-specific type containing four `poly8x16_t` vectors."],["poly8x8_t","ARM-specific 64-bit wide polynomial vector of eight packed `p8`."],["poly8x8x2_t","ARM-specific type containing two `poly8x8_t` vectors."],["poly8x8x3_t","ARM-specific type containing three `poly8x8_t` vectors."],["poly8x8x4_t","ARM-specific type containing four `poly8x8_t` vectors."],["uint16x4_t","ARM-specific 64-bit wide vector of four packed `u16`."],["uint16x8_t","ARM-specific 128-bit wide vector of eight packed `u16`."],["uint32x2_t","ARM-specific 64-bit wide vector of two packed `u32`."],["uint32x4_t","ARM-specific 128-bit wide vector of four packed `u32`."],["uint64x1_t","ARM-specific 64-bit wide vector of one packed `u64`."],["uint64x2_t","ARM-specific 128-bit wide vector of two packed `u64`."],["uint8x16_t","ARM-specific 128-bit wide vector of sixteen packed `u8`."],["uint8x16x2_t","ARM-specific type containing two `uint8x16_t` vectors."],["uint8x16x3_t","ARM-specific type containing three `uint8x16_t` vectors."],["uint8x16x4_t","ARM-specific type containing four `uint8x16_t` vectors."],["uint8x8_t","ARM-specific 64-bit wide vector of eight packed `u8`."],["uint8x8x2_t","ARM-specific type containing two `uint8x8_t` vectors."],["uint8x8x3_t","ARM-specific type containing three `uint8x8_t` vectors."],["uint8x8x4_t","ARM-specific type containing four `uint8x8_t` vectors."]]});